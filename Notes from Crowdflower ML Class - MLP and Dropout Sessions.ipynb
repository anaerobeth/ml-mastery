{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP and Dropout\n",
    "\n",
    "Notes from Lukas Biewald's [Crowdflower Machine Learning class](https://github.com/lukas/ml-class)\n",
    "\n",
    "### Multi-Layer Perceptron\n",
    "Load and preprocess the MNIST digits data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.py\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255.\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a fully-connected [Dense](https://keras.io/layers/core/#dense) layer with 100 units with `relu` as the [activation function](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.2666 - acc: 0.9239 - val_loss: 0.1534 - val_acc: 0.9547\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1207 - acc: 0.9649 - val_loss: 0.1003 - val_acc: 0.9693\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0844 - acc: 0.9748 - val_loss: 0.0876 - val_acc: 0.9727\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0649 - acc: 0.9805 - val_loss: 0.0760 - val_acc: 0.9759\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0506 - acc: 0.9844 - val_loss: 0.0808 - val_acc: 0.9761\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0414 - acc: 0.9875 - val_loss: 0.0723 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0764 - val_acc: 0.9765\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0279 - acc: 0.9911 - val_loss: 0.0750 - val_acc: 0.9771\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0212 - acc: 0.9938 - val_loss: 0.0766 - val_acc: 0.9783\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0195 - acc: 0.9941 - val_loss: 0.0784 - val_acc: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e2f8da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width, img_height)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "        callbacks=[tensorboard], epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the best `loss: 0.2428` and `acc: 0.9331` of the previous perceptron model, this model with 100 additional hidden layers achieved a loss of 0.0195 and accuracy of 0.9941 after 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Randomly select nodes to be [dropped-out](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) with a given probability for each update cycle: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.3618 - acc: 0.8915 - val_loss: 0.1661 - val_acc: 0.9513\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1943 - acc: 0.9404 - val_loss: 0.1158 - val_acc: 0.9656\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1555 - acc: 0.9515 - val_loss: 0.0984 - val_acc: 0.9692\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.1347 - acc: 0.9576 - val_loss: 0.0868 - val_acc: 0.9741\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1184 - acc: 0.9637 - val_loss: 0.0797 - val_acc: 0.9755\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1111 - acc: 0.9647 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1044 - acc: 0.9662 - val_loss: 0.0757 - val_acc: 0.9768\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0997 - acc: 0.9679 - val_loss: 0.0691 - val_acc: 0.9787\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0950 - acc: 0.9692 - val_loss: 0.0724 - val_acc: 0.9772\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0897 - acc: 0.9711 - val_loss: 0.0679 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11aeeadd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(img_width,img_height)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          callbacks=[tensorboard], epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying dropout regularization resulted in poorer accuracy performance after 10 epochs. Further optimizations such as using a larger network, increasing the learning rate and momentum, and constraining the size of the network weights may improve future performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IntroToTensorFlow]",
   "language": "python",
   "name": "conda-env-IntroToTensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
